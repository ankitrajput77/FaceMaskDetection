{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "import cv2\n",
    "from imutils.video import VideoStream\n",
    "import numpy as np\n",
    "from keras.applications.mobilenet_v2 import preprocess_input\n",
    "from keras.preprocessing.image import img_to_array, load_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mask Detector Model\n",
    "Mask_Model = load_model('../artifacts/Mask_detection_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Face detector models\n",
    "prototxt = r\"../artifacts/FaceModels/deploy.prototxt\"\n",
    "weights = r\"../artifacts/FaceModels/res10_300x300_ssd_iter_140000.caffemodel\"\n",
    "Face_Model = cv2.dnn.readNet(prototxt, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.engine.functional.Functional at 0x19e204481f0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Mask_Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "< cv2.dnn.Net 0000019E2026B970>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Face_Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_face_mask(frame, Face_Model, Mask_Model):\n",
    "\th, w = frame.shape[:2] # height n width \n",
    "\tblob = cv2.dnn.blobFromImage(image=frame, \n",
    "\t\t\t      \t\t\t\tscalefactor=1.0, \n",
    "\t\t\t\t\t\t\t\tsize=(224, 224), \n",
    "\t\t\t\t\t\t\t\tmean=(104.0, 177.0, 123.0)) # 4d blob\n",
    "\t# face detections\n",
    "\tFace_Model.setInput(blob)\n",
    "\tdetections = Face_Model.forward()\n",
    "\n",
    "\tfaces = [] # faces from Face Model\n",
    "\tlocs = [] # Location of faces\n",
    "\tpreds = [] # Prediction\n",
    "\n",
    "\n",
    "\tfor i in range(detections.shape[2]):\n",
    "\t\tprob = detections[0, 0, i, 2]\n",
    "\t\tif prob > 0.5: # thresh for face\n",
    "\t\t\tbox = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
    "\t\t\t(X_start, y_start, X_end, y_end) = box.astype(\"int\")\n",
    "\t\t\t(X_start, y_start) = (max(0, X_start), max(0, y_start))\n",
    "\t\t\t(X_end, y_end) = (min(w - 1, X_end), min(h - 1, y_end))\n",
    "\t\t\tface = frame[y_start:y_end, X_start:X_end]\n",
    "\t\t\tface = cv2.cvtColor(face, cv2.COLOR_BGR2RGB)\n",
    "\t\t\tface = cv2.resize(face, (224, 224))\n",
    "\t\t\tface = img_to_array(face)\n",
    "\t\t\tface = preprocess_input(face)\n",
    "\t\t\tfaces.append(face)\n",
    "\t\t\tlocs.append((X_start, y_start, X_end, y_end))\n",
    "\n",
    "\tif len(faces) > 0: # if faces\n",
    "\t\tfaces = np.array(faces, dtype=\"float32\")\n",
    "\t\tpreds = Mask_Model.predict(faces, batch_size=32)\n",
    "\treturn locs, preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = VideoStream(0).start()\n",
    "while True:\n",
    "\tframe = cap.read()\n",
    "\tlocs, preds = predict_face_mask(frame, Face_Model, Mask_Model)\n",
    "\n",
    "\t# for multiple faces\n",
    "\tfor box, pred in zip(locs, preds):\n",
    "\t\tX_start, y_start, X_end, y_end = box\n",
    "\t\tmask, withoutMask = pred\n",
    "\n",
    "\t\tif mask > withoutMask :\n",
    "\t\t\tlabel = \"Mask\"\n",
    "\t\telse:\n",
    "\t\t\tlabel = \"No Mask\"\n",
    "\n",
    "\t\tif label == \"Mask\":\n",
    "\t\t\tcolor = (0, 255, 0) # green \n",
    "\t\telse: \n",
    "\t\t\tcolor = (0, 0, 255) # red\n",
    "\t\t\n",
    "\t\tlabel = f\"{label}, {format(max(mask, withoutMask) * 100, '.2f')}%\"\n",
    "\t\tcv2.putText(img=frame, text=label, org=(X_start, y_start - 10), fontFace=cv2.FONT_HERSHEY_SIMPLEX, fontScale=0.45, color=color, thickness=2, lineType=cv2.LINE_AA)\n",
    "\t\tcv2.rectangle(img=frame, pt1=(X_start, y_start), pt2=(X_end, y_end), color=color, thickness=1)\n",
    "\n",
    "\tcv2.imshow(\"Mask Detector\", frame)\n",
    "\tif cv2.waitKey(2) == 27: # Esc button\n",
    "\t\tbreak\n",
    "cv2.destroyAllWindows()\n",
    "cap.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
